{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI essay count:  21387\n",
      "Human essay count:  30928\n",
      "Bounds for the entire dataset:  [(0.0, 7089.0), (7089.0, 8595.5), (8595.5, 9620.0), (9620.0, 10309.714285714283), (10309.714285714283, 11432.0), (11432.0, 12624.0), (12624.0, 28779.5)]\n",
      "Essay counts in each group for the entire dataset:  [7672, 7277, 7964, 6981, 7739, 7209, 7473]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import complex\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_rows', 5000000)\n",
    "dataset = pd.read_csv('train_v2_drct_02.csv')\n",
    "dataset = pd.read_csv('megaset.csv')\n",
    "dataset = pd.read_csv('metadataset.csv')\n",
    "\n",
    "# dataset = 'text' (sting), 'generated' (int) (0 for human, 1 for AI), 'complexity' (float)\n",
    "# dataset is sorted in ascending order accordding to the complexity\n",
    "\n",
    "human = dataset[dataset['generated'] == 0]\n",
    "ai = dataset[dataset['generated'] == 1]\n",
    "print(\"AI essay count: \", len(ai))\n",
    "print(\"Human essay count: \", len(human))\n",
    "\n",
    "verbs_dic = complex.read_file_to_dic('vocabulary/top_english_verbs_lower_100000.txt')\n",
    "verbs_dic2 = complex.read_file_to_dic('vocabulary/top_english_verbs_lower_10000.txt')\n",
    "verbs_dic = complex.read_file_to_dic('vocabulary/top_english_words_lower_1000000.txt')\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Divide the whole dataset into 10 groups based on complexity\n",
    "dataset['group'], total_bins = pd.qcut(dataset['complexity'], 7, labels=False, retbins=True)\n",
    "\n",
    "# Create a list of DataFrames for the essays, one DataFrame per group for the entire dataset\n",
    "divided_dataset = [dataset.loc[dataset['group'] == i, ['text', 'generated']] for i in range(7)]\n",
    "\n",
    "# Extracting bounds for each group for the entire dataset\n",
    "bounds = [(total_bins[i], total_bins[i+1]) for i in range(len(total_bins)-1)]\n",
    "\n",
    "print(\"Bounds for the entire dataset: \", bounds)\n",
    "\n",
    "# Optionally, print the number of essays in each group for the entire dataset\n",
    "print(\"Essay counts in each group for the entire dataset: \", [len(df) for df in divided_dataset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary_percentage(vocabulary_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary where keys are words\n",
    "    and values are the percentage of appearances of those words in the list.\n",
    "    \"\"\"\n",
    "    vocabulary_count = len(vocabulary_list)\n",
    "    word_counts = {} \n",
    "    # Count appearances of each word\n",
    "    for word in vocabulary_list:\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += 1\n",
    "        else:\n",
    "            word_counts[word] = 1\n",
    "    # Calculate percentage of appearances for each word\n",
    "    vocabulary_percentage = {word: (count / vocabulary_count) for word, count in word_counts.items()}\n",
    "    return vocabulary_percentage\n",
    "\n",
    "def convert_df_to_dics(df):\n",
    "    \"\"\"\n",
    "    Takes a DataFrame and returns two dictionaries of word prevalence, one for AI essays and one for human essays.\n",
    "    \"\"\"\n",
    "    ai_words = []\n",
    "    human_words = []\n",
    "    \n",
    "    ai_essays = df[df['generated'] == 1]['text']\n",
    "    for essay in ai_essays:\n",
    "        ai_words.extend(complex.clean_text(essay)) \n",
    "        \n",
    "    human_essays = df[df['generated'] == 0]['text']\n",
    "    for essay in human_essays:\n",
    "        human_words.extend(complex.clean_text(essay))  \n",
    "\n",
    "    human_dic = vocabulary_percentage(human_words)\n",
    "    ai_dic = vocabulary_percentage(ai_words)\n",
    "\n",
    "    #only verbs\n",
    "\n",
    "    # human_dic = {k: v for k, v in human_dic.items() if k in verbs_dic2}\n",
    "    # ai_dic = {k: v for k, v in ai_dic.items() if k in verbs_dic2}\n",
    "\n",
    "    return human_dic, ai_dic\n",
    "\n",
    "\n",
    "def get_prevalence_table(df):\n",
    "    \"\"\"\n",
    "    Takes a dataframe with human and AI essays and returns a DataFrame with the prevalence factor for each word.\n",
    "    \"\"\"\n",
    "    human_dic, ai_dic = convert_df_to_dics(df)\n",
    "    \n",
    "    prevalence_data = []\n",
    "    for word in set(list(ai_dic.keys()) + list(human_dic.keys())):\n",
    "        ai_prevalence = ai_dic.get(word, 0)\n",
    "        human_prevalence = human_dic.get(word, None)\n",
    "        if human_prevalence is not None:\n",
    "            if ai_prevalence == 0:\n",
    "                prevalence_factor = -25\n",
    "            elif human_prevalence > ai_prevalence:\n",
    "                if (ai_prevalence == 0):\n",
    "                    prevalence_factor = 50\n",
    "                else: \n",
    "                    prevalence_factor = -  human_prevalence / ai_prevalence \n",
    "            else:\n",
    "                prevalence_factor = ai_prevalence / human_prevalence \n",
    "            prevalence_data.append({'word': word, 'prevalence': prevalence_factor})\n",
    "    prevalence_table = pd.DataFrame(prevalence_data)\n",
    "    prevalence_table = prevalence_table.sort_values(by='prevalence', ascending=False)\n",
    "    return prevalence_table\n",
    "\n",
    "\n",
    "prevalence_tables = [get_prevalence_table(group_df) for group_df in divided_dataset]\n",
    "# convert prevalence_tables to dictionaries\n",
    "prevalence_dics = [dict(zip(table['word'], table['prevalence'])) for table in prevalence_tables]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prevalence_dic_for_essay(complexity_score):\n",
    "    \"\"\"\n",
    "    Given an essay's complexity score, find and return the appropriate prevalence dictionary.\n",
    "    \n",
    "    :param complexity_score: The complexity score of the essay.\n",
    "    :return: The prevalence dictionary for the complexity group the essay falls into.\n",
    "    \"\"\"\n",
    "    # Iterate through the bounds to find the right complexity group\n",
    "    for i, (lower_bound, upper_bound) in enumerate(bounds):\n",
    "        if lower_bound <= complexity_score <= upper_bound:\n",
    "            return prevalence_dics[i]\n",
    "    # If the complexity score doesn't fall within any bounds, return None or handle appropriately\n",
    "    return prevalence_dics[-1]\n",
    "\n",
    "\n",
    "def predict_ai(essay, print_prevalence=False):\n",
    "    \"\"\"\n",
    "    Given an essay and a prevalence table, predict whether the essay is AI-generated or human-written.\n",
    "    \n",
    "    :param essay: The essay to predict.\n",
    "    :param table: The prevalence table to use for prediction.\n",
    "    :return: 1 if the essay is predicted to be AI-generated, 0 if human-written.\n",
    "    \"\"\"\n",
    "    prevalence_dict = get_prevalence_dic_for_essay(complex.calculate_complexity(essay, verbs_dic))\n",
    "    prevalence_score = 0\n",
    "    words = complex.clean_text(essay)\n",
    "    for word in words:\n",
    "        # check if the word is in the prevalence dictionary\n",
    "        if word in prevalence_dict:\n",
    "            prevalence = prevalence_dict.get(word, 0)\n",
    "        else:\n",
    "            prevalence = 0\n",
    "        if (prevalence > 0):\n",
    "            prevalence -= 1\n",
    "        else:\n",
    "            prevalence += 1\n",
    "        prevalence_score += prevalence\n",
    "    if print_prevalence:\n",
    "        print(prevalence_score)\n",
    "    return 1 if prevalence_score > 0 else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>prevalence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33950</th>\n",
       "      <td>cooperation</td>\n",
       "      <td>258.113566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6830</th>\n",
       "      <td>embrace</td>\n",
       "      <td>210.033588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>well-rounded</td>\n",
       "      <td>210.033588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>cooperate</td>\n",
       "      <td>206.237801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25052</th>\n",
       "      <td>critically</td>\n",
       "      <td>194.850437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8725</th>\n",
       "      <td>lifelong</td>\n",
       "      <td>172.075711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15501</th>\n",
       "      <td>preferences</td>\n",
       "      <td>167.014661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30687</th>\n",
       "      <td>teamwork</td>\n",
       "      <td>167.014661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>travelling</td>\n",
       "      <td>160.688348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20405</th>\n",
       "      <td>customs</td>\n",
       "      <td>156.892560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28784</th>\n",
       "      <td>convenience</td>\n",
       "      <td>156.892560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30639</th>\n",
       "      <td>specialize</td>\n",
       "      <td>154.362035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28567</th>\n",
       "      <td>standardized</td>\n",
       "      <td>154.362035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30588</th>\n",
       "      <td>attractions</td>\n",
       "      <td>139.178884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14079</th>\n",
       "      <td>tour</td>\n",
       "      <td>134.117833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>external</td>\n",
       "      <td>126.526258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19751</th>\n",
       "      <td>collaboration</td>\n",
       "      <td>123.995733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22809</th>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>123.995733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>fulfilling</td>\n",
       "      <td>120.199945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>prioritize</td>\n",
       "      <td>116.404157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  prevalence\n",
       "33950    cooperation  258.113566\n",
       "6830         embrace  210.033588\n",
       "2901    well-rounded  210.033588\n",
       "1651       cooperate  206.237801\n",
       "25052     critically  194.850437\n",
       "8725        lifelong  172.075711\n",
       "15501    preferences  167.014661\n",
       "30687       teamwork  167.014661\n",
       "9881      travelling  160.688348\n",
       "20405        customs  156.892560\n",
       "28784    convenience  156.892560\n",
       "30639     specialize  154.362035\n",
       "28567   standardized  154.362035\n",
       "30588    attractions  139.178884\n",
       "14079           tour  134.117833\n",
       "4968        external  126.526258\n",
       "19751  collaboration  123.995733\n",
       "22809     unfamiliar  123.995733\n",
       "3011      fulfilling  120.199945\n",
       "15997     prioritize  116.404157"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('customs' in verbs_dic)\n",
    "prevalence_tables[0].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.29%\n",
      "False Positive Rate (FPR): 13.1648%\n",
      "False Negative Rate (FNR): 14.7001%\n"
     ]
    }
   ],
   "source": [
    "test_data = dataset\n",
    "\n",
    "# replace name of the column 'label' with 'generated'\n",
    "test_data = pd.read_csv('human_expert_essays.csv')\n",
    "test_data = pd.read_csv('train_v2_drct_02.csv')\n",
    "test_data = pd.read_csv('metadataset.csv')\n",
    "test_data = pd.read_csv('final_test.csv').sample(10000)\n",
    "\n",
    "test_data['Verdict'] = test_data['text'].apply(predict_ai)\n",
    "\n",
    "# Determine AI prediction based on the verdict\n",
    "test_data['Prediction'] = test_data['Verdict']\n",
    "\n",
    "generated_column = 'generated'\n",
    "# Calculate overall accuracy and error rates\n",
    "accuracy = (test_data['Prediction'] == test_data[generated_column]).mean()\n",
    "fp = test_data[(test_data['Prediction'] == 1) & (test_data[generated_column] == 0)].shape[0]\n",
    "fn = test_data[(test_data['Prediction'] == 0) & (test_data[generated_column] == 1)].shape[0]\n",
    "tp = test_data[(test_data['Prediction'] == 1) & (test_data[generated_column] == 1)].shape[0]\n",
    "tn = test_data[(test_data['Prediction'] == 0) & (test_data[generated_column] == 0)].shape[0]\n",
    "\n",
    "digits = 4\n",
    "accuracy = round(100 * accuracy, digits)\n",
    "\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "fpr = round(100 * fpr, digits)\n",
    "fnr = round(100 * fnr, digits)\n",
    "                                   \n",
    "\n",
    "def mean(listx):\n",
    "    total = 0\n",
    "    for i in range(len(listx)):\n",
    "        total += listx[i]\n",
    "    return total / len(listx)\n",
    "    \n",
    "\n",
    "print(f\"Accuracy: {accuracy}%\")\n",
    "print(f\"False Positive Rate (FPR): {fpr}%\")\n",
    "print(f\"False Negative Rate (FNR): {fnr}%\")\n",
    "# print(f\"Average prevalence = {mean(prev)}%\")\n",
    "# print(f\"Prevalence std = {np.std(prev)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_ai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      2\u001b[0m     text \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 3\u001b[0m verdict \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_ai\u001b[49m(text, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(verdict)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_ai' is not defined"
     ]
    }
   ],
   "source": [
    "with open('input.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "verdict = predict_ai(text, True)\n",
    "print(verdict)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch Reading Ease: 86.74\n",
      "43.721818181818215\n",
      "OrderedDict([('readability grades', OrderedDict([('Kincaid', 20.824545454545454), ('ARI', 23.946590909090908), ('Coleman-Liau', 5.97795265909091), ('FleschReadingEase', 43.721818181818215), ('GunningFogIndex', 25.090909090909093), ('LIX', 66.36363636363636), ('SMOGIndex', 14.291589790636214), ('RIX', 6.25), ('DaleChallIndex', 8.589454545454545)])), ('sentence info', OrderedDict([('characters_per_word', 3.7954545454545454), ('syll_per_word', 1.268181818181818), ('words_per_sentence', 55.0), ('sentences_per_paragraph', 1.0), ('type_token_ratio', 0.4), ('characters', 835), ('syllables', 279), ('words', 220), ('wordtypes', 88), ('sentences', 4), ('paragraphs', 4), ('long_words', 25), ('complex_words', 17), ('complex_words_dc', 31)])), ('word usage', OrderedDict([('tobeverb', 9), ('auxverb', 8), ('conjunction', 4), ('pronoun', 38), ('preposition', 24), ('nominalization', 0)])), ('sentence beginnings', OrderedDict([('pronoun', 2), ('interrogative', 0), ('article', 0), ('subordination', 0), ('conjunction', 0), ('preposition', 0)]))])\n",
      "Lexical Diversity: 0.5517241379310345\n"
     ]
    }
   ],
   "source": [
    "import textstat\n",
    "\n",
    "with open('input.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "score = textstat.flesch_reading_ease(text)\n",
    "print(f\"Flesch Reading Ease: {score}\")\n",
    "\n",
    "\n",
    "import readability\n",
    "results = readability.getmeasures(text, lang='en')\n",
    "print(results['readability grades']['FleschReadingEase'])\n",
    "print(results)\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "words = word_tokenize(text)\n",
    "words_without_stopwords = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "lexical_diversity = len(set(words_without_stopwords)) / len(words_without_stopwords)\n",
    "print(f\"Lexical Diversity: {lexical_diversity}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

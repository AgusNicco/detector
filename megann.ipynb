{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/agus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import bigrams\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "from nltk import trigrams\n",
    "from textstat import flesch_reading_ease\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the two-word prevalence table\n",
    "two_word_prevalence_table = pd.read_csv('two_word_prevalence_table.csv')\n",
    "two_word_prevalence_dict = two_word_prevalence_table.set_index('Bigram')['Prevalence_Factor'].to_dict()\n",
    "\n",
    "prevalence_table = pd.read_csv('prevalence_table.csv')\n",
    "prevalence_dict = prevalence_table.set_index('Word')['Prevalence_Factor'].to_dict()\n",
    "\n",
    "# Load the three-word prevalence table\n",
    "three_word_prevalence_table = pd.read_csv('three_word_prevalence_table.csv')\n",
    "three_word_prevalence_dict = three_word_prevalence_table.set_index('Trigram')['Prevalence_Factor'].to_dict()\n",
    "\n",
    "four_word_prevalence_table = pd.read_csv('four_word_prevalence_table.csv')\n",
    "four_word_prevalence_dict = four_word_prevalence_table.set_index('Fourgram')['Prevalence_Factor'].to_dict()\n",
    "\n",
    "\n",
    "def get_sentence_prevalence_array(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    clean_sentences = [clean_text(sentence) for sentence in sentences]\n",
    "    output = []\n",
    "    for sentence in clean_sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "        prevalences = [get_prevalence_word(word) for word in words]\n",
    "        prevalence_array = prevalences[:30] + [0] * (30 - len(prevalences))\n",
    "        output.append(prevalence_array)\n",
    "    return output\n",
    "\n",
    "def get_sentence_prevalence_array(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    clean_sentences = [clean_text(sentence) for sentence in sentences if len(word_tokenize(sentence)) <= 30]  # Only consider sentences with 30 or fewer words\n",
    "    output = []\n",
    "    for sentence in clean_sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "        prevalences = [get_prevalence_word(word) for word in words]\n",
    "        prevalence_array = prevalences[:30] + [0] * (30 - len(prevalences))\n",
    "        output.append(prevalence_array)\n",
    "    return output\n",
    "\n",
    "def get_prevalence_array(text):\n",
    "    text = clean_text(text)  # Clean the text using the previously defined function\n",
    "    words = word_tokenize(text)  # Tokenize the text into words\n",
    "    prevalences = [get_prevalence_word(word) for word in words]  # Get prevalence scores for each word\n",
    "    # Ensure the list has 1000 cells, filling empty cells with 0\n",
    "    prevalence_array = prevalences[:1000] + [0] * (1000 - len(prevalences))\n",
    "    return prevalence_array\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean the text for analysis.\"\"\"\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "def get_prevalence_word(word):\n",
    "    word = str(word)\n",
    "    word = word.lower()\n",
    "    if word in prevalence_dict:\n",
    "        return prevalence_dict[word]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_text_length(text):\n",
    "    text = str(text)\n",
    "    return len(text.split())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/agus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Assuming the get_sentence_prevalence_array function is defined as discussed earlier\n",
    "\n",
    "def transform_dataset(input_path, output_path):\n",
    "    # Load dataset\n",
    "    data = pd.read_csv(input_path)\n",
    "    \n",
    "    transformed_data = []\n",
    "    for index, row in data.iterrows():\n",
    "        text = row['text']\n",
    "        generated = row['generated']\n",
    "        sentence_prevalences = get_sentence_prevalence_array(text)\n",
    "        \n",
    "        for sentence_array in sentence_prevalences:\n",
    "            # Create a dictionary for each sentence with its prevalence array and generated status\n",
    "            sentence_data = {'generated': generated}\n",
    "            for i, prevalence in enumerate(sentence_array, start=1):\n",
    "                sentence_data[f'word_{i}'] = prevalence\n",
    "            transformed_data.append(sentence_data)\n",
    "    \n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    transformed_df = pd.DataFrame(transformed_data)\n",
    "    \n",
    "    # Save the transformed DataFrame to a new CSV file\n",
    "    transformed_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Define your input and output file paths\n",
    "input_path = 'final_test2.csv'\n",
    "output_path = 'final_test2_sentences.csv'\n",
    "\n",
    "# Call the function to transform the dataset\n",
    "transform_dataset(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('final_test2.csv')\n",
    "datset = dataset[dataset['text'].apply(lambda x: get_text_length(x) > 0 and get_text_length(x) <= 1000)]\n",
    "\n",
    "# Apply get_prevalence_array to each text in the dataset\n",
    "prevalence_arrays = dataset['text'].apply(get_prevalence_array)\n",
    "\n",
    "# Convert list of lists into a DataFrame\n",
    "prevalence_df = pd.DataFrame(prevalence_arrays.tolist(), columns=[str(i) for i in range(1, 1001)])\n",
    "\n",
    "# Prefix the 'generated' column from the original dataset\n",
    "new_data = pd.concat([dataset['generated'].reset_index(drop=True), prevalence_df], axis=1)\n",
    "\n",
    "# Save the new dataset to a CSV file\n",
    "new_data.to_csv('transformed_final_test2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.34968978\n",
      "Iteration 2, loss = 0.34296998\n",
      "Iteration 3, loss = 0.33935855\n",
      "Iteration 4, loss = 0.33729877\n",
      "Iteration 5, loss = 0.33557947\n",
      "Iteration 6, loss = 0.33391905\n",
      "Iteration 7, loss = 0.33250285\n",
      "Iteration 8, loss = 0.33130897\n",
      "Iteration 9, loss = 0.33036492\n",
      "Iteration 10, loss = 0.32940762\n",
      "Iteration 11, loss = 0.32859745\n",
      "Iteration 12, loss = 0.32778653\n",
      "Iteration 13, loss = 0.32706837\n",
      "Iteration 14, loss = 0.32640174\n",
      "Iteration 15, loss = 0.32580664\n",
      "Iteration 16, loss = 0.32519086\n",
      "Iteration 17, loss = 0.32460011\n",
      "Iteration 18, loss = 0.32411817\n",
      "Iteration 19, loss = 0.32366582\n",
      "Iteration 20, loss = 0.32307092\n",
      "Iteration 21, loss = 0.32265984\n",
      "Iteration 22, loss = 0.32219341\n",
      "Iteration 23, loss = 0.32170646\n",
      "Iteration 24, loss = 0.32143901\n",
      "Iteration 25, loss = 0.32095724\n",
      "Iteration 26, loss = 0.32064097\n",
      "Iteration 27, loss = 0.32039053\n",
      "Iteration 28, loss = 0.31998099\n",
      "Iteration 29, loss = 0.31976554\n",
      "Iteration 30, loss = 0.31954190\n",
      "Iteration 31, loss = 0.31927056\n",
      "Iteration 32, loss = 0.31898038\n",
      "Iteration 33, loss = 0.31883902\n",
      "Iteration 34, loss = 0.31845112\n",
      "Iteration 35, loss = 0.31835204\n",
      "Iteration 36, loss = 0.31817610\n",
      "Iteration 37, loss = 0.31791164\n",
      "Iteration 38, loss = 0.31774836\n",
      "Iteration 39, loss = 0.31749455\n",
      "Iteration 40, loss = 0.31726676\n",
      "Iteration 41, loss = 0.31713720\n",
      "Iteration 42, loss = 0.31687544\n",
      "Iteration 43, loss = 0.31675664\n",
      "Iteration 44, loss = 0.31668920\n",
      "Iteration 45, loss = 0.31632354\n",
      "Iteration 46, loss = 0.31613304\n",
      "Iteration 47, loss = 0.31609108\n",
      "Iteration 48, loss = 0.31595472\n",
      "Iteration 49, loss = 0.31578697\n",
      "Iteration 50, loss = 0.31568493\n",
      "Iteration 51, loss = 0.31550420\n",
      "Iteration 52, loss = 0.31544341\n",
      "Iteration 53, loss = 0.31520124\n",
      "Iteration 54, loss = 0.31518518\n",
      "Iteration 55, loss = 0.31497910\n",
      "Iteration 56, loss = 0.31497342\n",
      "Iteration 57, loss = 0.31490163\n",
      "Iteration 58, loss = 0.31455284\n",
      "Iteration 59, loss = 0.31439708\n",
      "Iteration 60, loss = 0.31441305\n",
      "Iteration 61, loss = 0.31439854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 86.95%\n",
      "Accuracy on the test set: 83.90%\n",
      "False Positive Rate on test data: 8.97%\n",
      "False Negative Rate on test data: 31.45%\n",
      "Average error rate on test data: 20.21%\n",
      "Score: 14.32\n",
      "Confusion Matrix for the test data:\n",
      "[[62175  6130]\n",
      " [ 9969 21726]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "path_train = \"transformed_megaset4_sentences.csv\"\n",
    "train_data = pd.read_csv(path_train)\n",
    "\n",
    "# train_data_dropped = train_data.drop(train_data[train_data['generated'] == 1].sample(n=1).index)\n",
    "# train_data = train_data[train_data['text'].apply(lambda x: get_text_length(x) >= 300 and get_text_length(x) <= 1000)]\n",
    "\n",
    "path_test = \"final_test2_sentences.csv\"\n",
    "test_data = pd.read_csv(path_test).sample(100000)\n",
    "# test_data = test_data[test_data['text'].apply(lambda x: get_text_length(x) >= 300 and get_text_length(x) <= 10000)]\n",
    "\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def tostr(x):\n",
    "    return \"word_\"+str(x)\n",
    "\n",
    "x_features = [tostr(i) for i in range(1, 30)]\n",
    "\n",
    "# Prepare the features and target for the training data\n",
    "X_train = train_data[x_features]\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train = train_data['generated']\n",
    "\n",
    "# Prepare the features and target for the testing data\n",
    "X_test = test_data[x_features]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test = test_data['generated']\n",
    "\n",
    "# Initialize MLPClassifier with a specified architecture\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,100,100,100,100,100,100,100), activation='relu', \n",
    "                        solver='adam', max_iter=200, random_state=12, verbose=True)\n",
    "\n",
    "# Train the classifier on the scaled training data\n",
    "mlp_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the scaled testing data\n",
    "y_pred_test = mlp_clf.predict(X_test_scaled)\n",
    "# Make predictions on the scaled training data for overfitting check\n",
    "y_pred_train = mlp_clf.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate the accuracy on the testing data\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "# Evaluate the accuracy on the training data\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Output the accuracies\n",
    "print(f\"Accuracy on the training set: {accuracy_train * 100:.2f}%\")\n",
    "print(f\"Accuracy on the test set: {accuracy_test * 100:.2f}%\")\n",
    "\n",
    "# If the accuracy on the training set is significantly higher than on the test set,\n",
    "# it may indicate overfitting.\n",
    "\n",
    "# Calculate the confusion matrix for test data to get false positive and false negative rates\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = conf_matrix_test.ravel()\n",
    "\n",
    "# Calculate rates\n",
    "false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "# Print the rates\n",
    "print(f\"False Positive Rate on test data: {false_positive_rate * 100:.2f}%\")\n",
    "print(f\"False Negative Rate on test data: {false_negative_rate * 100:.2f}%\")\n",
    "print(f\"Average error rate on test data: {(false_positive_rate*100 + false_negative_rate*100) / 2 :.2f}%\")\n",
    "\n",
    "score = 1 / false_negative_rate + 1 / false_positive_rate\n",
    "print(f\"Score: {score:.2f}\")\n",
    "\n",
    "# Print the confusion matrix for the test data\n",
    "print(\"Confusion Matrix for the test data:\")\n",
    "print(conf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.13%\n",
      "False Positive Rate: 15.40%\n",
      "False Negative Rate: 29.44%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming the train_data is loaded as shown previously\n",
    "path_train = \"final_test2_sentences.csv\"\n",
    "train_data = pd.read_csv(path_train)\n",
    "\n",
    "# Define the predict function\n",
    "def predict(sentence):\n",
    "    prevalence = sum(sentence)\n",
    "    return 1 if prevalence > 0 else 0\n",
    "\n",
    "# Extract sentence prevalence factors and the 'generated' column\n",
    "sentence_columns = [f'word_{i}' for i in range(1, 31)]  # Adjust based on actual column names\n",
    "X = train_data[sentence_columns].values\n",
    "y_true = train_data['generated'].values\n",
    "\n",
    "# Make predictions\n",
    "y_pred = [predict(row) for row in X]\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum(int(pred == true) for pred, true in zip(y_pred, y_true))\n",
    "accuracy = correct_predictions / len(y_true)\n",
    "\n",
    "# Calculate confusion matrix to get false positive and false negative rates\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "# Calculate rates\n",
    "false_positive_rate = fp / (fp + tn)\n",
    "false_negative_rate = fn / (fn + tp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"False Positive Rate: {false_positive_rate * 100:.2f}%\")\n",
    "print(f\"False Negative Rate: {false_negative_rate * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.38253036\n",
      "Iteration 2, loss = 0.35646761\n",
      "Iteration 3, loss = 0.35583621\n",
      "Iteration 4, loss = 0.35540517\n",
      "Iteration 5, loss = 0.35519821\n",
      "Iteration 6, loss = 0.35486349\n",
      "Iteration 7, loss = 0.35483404\n",
      "Iteration 8, loss = 0.35472635\n",
      "Iteration 9, loss = 0.35466861\n",
      "Iteration 10, loss = 0.35467789\n",
      "Iteration 11, loss = 0.35467291\n",
      "Iteration 12, loss = 0.35467595\n",
      "Iteration 13, loss = 0.35465823\n",
      "Iteration 14, loss = 0.35465838\n",
      "Iteration 15, loss = 0.35464592\n",
      "Iteration 16, loss = 0.35461727\n",
      "Iteration 17, loss = 0.35397195\n",
      "Iteration 18, loss = 0.35392455\n",
      "Iteration 19, loss = 0.35391706\n",
      "Iteration 20, loss = 0.35391713\n",
      "Iteration 21, loss = 0.35389435\n",
      "Iteration 22, loss = 0.35390159\n",
      "Iteration 23, loss = 0.35390849\n",
      "Iteration 24, loss = 0.35388773\n",
      "Iteration 25, loss = 0.35389409\n",
      "Iteration 26, loss = 0.35388803\n",
      "Iteration 27, loss = 0.35389251\n",
      "Iteration 28, loss = 0.35388107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy on the training set: 85.17%\n",
      "Accuracy on the test set: 82.53%\n",
      "False Positive Rate on test data: 7.68%\n",
      "False Negative Rate on test data: 38.60%\n",
      "Average error rate on test data: 23.14%\n",
      "Score: 15.60\n",
      "Confusion Matrix for the test data:\n",
      "[[63095  5252]\n",
      " [12217 19436]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "path_train = \"transformed_megaset4_sentences.csv\"\n",
    "train_data = pd.read_csv(path_train)\n",
    "\n",
    "# train_data_dropped = train_data.drop(train_data[train_data['generated'] == 1].sample(n=1).index)\n",
    "# train_data = train_data[train_data['text'].apply(lambda x: get_text_length(x) >= 300 and get_text_length(x) <= 1000)]\n",
    "\n",
    "path_test = \"final_test2_sentences.csv\"\n",
    "test_data = pd.read_csv(path_test).sample(100000)\n",
    "# test_data = test_data[test_data['text'].apply(lambda x: get_text_length(x) >= 300 and get_text_length(x) <= 10000)]\n",
    "\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def tostr(x):\n",
    "    return \"word_\"+str(x)\n",
    "\n",
    "x_features = [tostr(i) for i in range(1, 30)]\n",
    "\n",
    "# Prepare the features and target for the training data\n",
    "X_train = train_data[x_features]\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train = train_data['generated']\n",
    "\n",
    "# Prepare the features and target for the testing data\n",
    "X_test = test_data[x_features]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test = test_data['generated']\n",
    "\n",
    "# Initialize MLPClassifier with a specified architecture\n",
    "\n",
    "mlp_clf2 = MLPClassifier(hidden_layer_sizes=(2), activation='relu', \n",
    "                        solver='adam', max_iter=999999, random_state=12, verbose=True)\n",
    "\n",
    "# Train the classifier on the scaled training data\n",
    "mlp_clf2.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the scaled testing data\n",
    "y_pred_test = mlp_clf2.predict(X_test_scaled)\n",
    "# Make predictions on the scaled training data for overfitting check\n",
    "y_pred_train = mlp_clf2.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate the accuracy on the testing data\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "# Evaluate the accuracy on the training data\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Output the accuracies\n",
    "print(f\"Accuracy on the training set: {accuracy_train * 100:.2f}%\")\n",
    "print(f\"Accuracy on the test set: {accuracy_test * 100:.2f}%\")\n",
    "\n",
    "# If the accuracy on the training set is significantly higher than on the test set,\n",
    "# it may indicate overfitting.\n",
    "\n",
    "# Calculate the confusion matrix for test data to get false positive and false negative rates\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = conf_matrix_test.ravel()\n",
    "\n",
    "# Calculate rates\n",
    "false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "# Print the rates\n",
    "print(f\"False Positive Rate on test data: {false_positive_rate * 100:.2f}%\")\n",
    "print(f\"False Negative Rate on test data: {false_negative_rate * 100:.2f}%\")\n",
    "print(f\"Average error rate on test data: {(false_positive_rate*100 + false_negative_rate*100) / 2 :.2f}%\")\n",
    "\n",
    "score = 1 / false_negative_rate + 1 / false_positive_rate\n",
    "print(f\"Score: {score:.2f}\")\n",
    "\n",
    "# Print the confusion matrix for the test data\n",
    "print(\"Confusion Matrix for the test data:\")\n",
    "print(conf_matrix_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Accuracy on the training set: 85.67%\n",
      "Accuracy on the test set: 83.10%\n",
      "False Positive Rate on test data: 7.82%\n",
      "False Negative Rate on test data: 36.35%\n",
      "Average error rate on test data: 22.09%\n",
      "Score: 15.54\n",
      "Confusion Matrix for the test data:\n",
      "[[62835  5331]\n",
      " [11572 20262]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "path_train = \"transformed_megaset4_sentences.csv\"\n",
    "train_data = pd.read_csv(path_train).sample(1000000)\n",
    "\n",
    "path_test = \"final_test2_sentences.csv\"\n",
    "test_data = pd.read_csv(path_test).sample(100000)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def tostr(x):\n",
    "    return \"word_\"+str(x)\n",
    "\n",
    "x_features = [tostr(i) for i in range(1, 30)]\n",
    "\n",
    "# Prepare the features and target for the training data\n",
    "X_train = train_data[x_features]\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train = train_data['generated']\n",
    "\n",
    "# Prepare the features and target for the testing data\n",
    "X_test = test_data[x_features]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test = test_data['generated']\n",
    "\n",
    "# Initialize KNeighborsClassifier\n",
    "print(\"Starting training\")\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=51)\n",
    "\n",
    "# Train the classifier on the scaled training data\n",
    "knn_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the scaled testing data\n",
    "y_pred_test = knn_clf.predict(X_test_scaled)\n",
    "# Make predictions on the scaled training data for overfitting check\n",
    "y_pred_train = knn_clf.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate the accuracy on the testing data\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "# Evaluate the accuracy on the training data\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Output the accuracies\n",
    "print(f\"Accuracy on the training set: {accuracy_train * 100:.2f}%\")\n",
    "print(f\"Accuracy on the test set: {accuracy_test * 100:.2f}%\")\n",
    "\n",
    "# Calculate the confusion matrix for test data to get false positive and false negative rates\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = conf_matrix_test.ravel()\n",
    "\n",
    "# Calculate rates\n",
    "false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "# Print the rates\n",
    "print(f\"False Positive Rate on test data: {false_positive_rate * 100:.2f}%\")\n",
    "print(f\"False Negative Rate on test data: {false_negative_rate * 100:.2f}%\")\n",
    "print(f\"Average error rate on test data: {(false_positive_rate*100 + false_negative_rate*100) / 2 :.2f}%\")\n",
    "\n",
    "score = 1 / false_negative_rate + 1 / false_positive_rate\n",
    "print(f\"Score: {score:.2f}\")\n",
    "\n",
    "# Print the confusion matrix for the test data\n",
    "print(\"Confusion Matrix for the test data:\")\n",
    "print(conf_matrix_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import complex\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "words1 = complex.read_file_to_dic('vocabulary/top_english_adjs_lower_100000.txt')\n",
    "words2 = complex.read_file_to_dic('vocabulary/top_english_words_lower_100000.txt')\n",
    "words3 = complex.read_file_to_dic('vocabulary/top_english_verbs_lower_100000.txt')\n",
    "words4 = complex.read_file_to_dic('vocabulary/top_english_nouns_lower_100000.txt')\n",
    "\n",
    "def calculate_complexity(text: str) -> float:\n",
    "    words = complex.clean_text(text)\n",
    "    complexity = 0.0\n",
    "    values = []\n",
    "    for word in words:\n",
    "        if words1.get(word) is not None:\n",
    "            value = words1[word] +0.01\n",
    "            # value = math.log2(value)\n",
    "            complexity += value\n",
    "            values.append(value)\n",
    "        elif words3.get(word) is not None:\n",
    "            value = words3[word] +0.01\n",
    "            #value = math.log2(value)\n",
    "            complexity += value\n",
    "            values.append(value)\n",
    "        # elif words4.get(word) is not None:\n",
    "        #     value = words4[word] +0.01\n",
    "        #     value = math.log2(value)\n",
    "        #     complexity += value\n",
    "        #     values.append(value)\n",
    "    if values:\n",
    "        return np.mean(values)\n",
    "    else:\n",
    "        return complexity  # Return 0 or a default value if no words match\n",
    "    \n",
    "def is_verb(word: str) -> bool:\n",
    "    if words3.get(word) is not None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def is_adj(word: str) -> bool:\n",
    "    if words1.get(word) is not None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/agus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import bigrams\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "from nltk import trigrams\n",
    "from textstat import flesch_reading_ease\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the two-word prevalence table\n",
    "two_word_prevalence_table = pd.read_csv('two_word_prevalence_table.csv')\n",
    "two_word_prevalence_dict = two_word_prevalence_table.set_index('Bigram')['Prevalence_Factor'].to_dict()\n",
    "\n",
    "prevalence_table = pd.read_csv('prevalence_table.csv')\n",
    "prevalence_dict = prevalence_table.set_index('Word')['Prevalence_Factor'].to_dict()\n",
    "\n",
    "# Load the three-word prevalence table\n",
    "three_word_prevalence_table = pd.read_csv('three_word_prevalence_table.csv')\n",
    "three_word_prevalence_dict = three_word_prevalence_table.set_index('Trigram')['Prevalence_Factor'].to_dict()\n",
    "\n",
    "four_word_prevalence_table = pd.read_csv('four_word_prevalence_table.csv')\n",
    "four_word_prevalence_dict = four_word_prevalence_table.set_index('Fourgram')['Prevalence_Factor'].to_dict()\n",
    "\n",
    "five_word_prevalence_table = pd.read_csv('five_word_prevalence_table.csv')\n",
    "five_word_prevalence_dict = five_word_prevalence_table.set_index('Fivegram')['Prevalence_Factor'].to_dict()\n",
    "\n",
    "\n",
    "def get_text_fivegram_prevalence(text):\n",
    "    \"\"\"Calculate the total prevalence factor for all fivegrams in the text.\"\"\"\n",
    "    text = clean_text(text)  #\n",
    "    words = word_tokenize(text)\n",
    "    total_prevalence = 0\n",
    "    for i in range(len(words)):\n",
    "        if i + 4 < len(words):\n",
    "            fivegram = [words[i], words[i + 1], words[i + 2], words[i + 3], words[i + 4]]\n",
    "            total_prevalence += five_word_prevalence_dict.get(' '.join(fivegram), 0)\n",
    "    return total_prevalence\n",
    "\n",
    "def get_prevalence_array(text):\n",
    "    text = clean_text(text)  # Clean the text using the previously defined function\n",
    "    words = word_tokenize(text)  # Tokenize the text into words\n",
    "    prevalences = [get_prevalence_word(word) for word in words]  # Get prevalence scores for each word\n",
    "    # Ensure the list has 1000 cells, filling empty cells with 0\n",
    "    prevalence_array = prevalences[:1000] + [0] * (1000 - len(prevalences))\n",
    "    return prevalence_array\n",
    "\n",
    "def get_text_fourgram_prevalence(text):\n",
    "    \"\"\"Calculate the total prevalence factor for all fourgrams in the text.\"\"\"\n",
    "    text = clean_text(text)  #\n",
    "    words = word_tokenize(text)\n",
    "    total_prevalence = 0\n",
    "    for i in range(len(words)):\n",
    "        if i + 3 < len(words):\n",
    "            fourgram = [words[i], words[i + 1], words[i + 2], words[i + 3]]\n",
    "            total_prevalence += four_word_prevalence_dict.get(' '.join(fourgram), 0)\n",
    "    return total_prevalence\n",
    "\n",
    "def get_text_trigram_prevalence(text):\n",
    "    \"\"\"Calculate the total prevalence factor for all trigrams in the text.\"\"\"\n",
    "    text = clean_text(text)  #\n",
    "    words = word_tokenize(text)\n",
    "    total_prevalence = 0\n",
    "    for i in range(len(words)):\n",
    "        if i + 2 < len(words):\n",
    "            trigram = [words[i], words[i + 1], words[i + 2]]\n",
    "            total_prevalence += three_word_prevalence_dict.get(' '.join(trigram), 0)\n",
    "    return total_prevalence\n",
    "\n",
    "\n",
    "# ranges:  (-628.88, 51.78), 2: (51.79, 62.17), 3: (62.18, 69.82), 4: (69.86, 77.67), 5: (77.71, 105.45)}\n",
    "# calculate readability using text textstat.flesch_reading_ease(text)\n",
    "weighted_prevalence_dicts = {}\n",
    "for i in range(1, 6):\n",
    "    table = pd.read_csv(f'weighted_prevalence{i}.csv')\n",
    "    weighted_prevalence_dicts[i] = table.set_index('word')['prevalence'].to_dict()\n",
    "\n",
    "\n",
    "def get_text_weighted_prevalence(text):\n",
    "    readability = calculate_readability(text)\n",
    "    # Determine the group based on readability\n",
    "    if readability <= 51.78:\n",
    "        group = 1\n",
    "    elif readability <= 62.17:\n",
    "        group = 2\n",
    "    elif readability <= 69.82:\n",
    "        group = 3\n",
    "    elif readability <= 77.67:\n",
    "        group = 4\n",
    "    else:\n",
    "        group = 5\n",
    "    # Calculate the weighted prevalence for words in the text\n",
    "    words = clean_text(text)\n",
    "    prevalence_scores = [weighted_prevalence_dicts[group].get(word, 0) for word in words]\n",
    "    \n",
    "    # Calculate and return the average weighted prevalence\n",
    "    if prevalence_scores:\n",
    "        return np.mean(prevalence_scores)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculate_readability(text):\n",
    "    return flesch_reading_ease(text)\n",
    "\n",
    "def get_text_bigram_prevalence(text):\n",
    "    \"\"\"Calculate the total prevalence factor for all bigrams in the text.\"\"\"\n",
    "    text = clean_text(text)  # Clean the text\n",
    "    words = word_tokenize(text)  # Tokenize the text into words\n",
    "    bigram_sequence = list(bigrams(words))  # Create bigrams from the words\n",
    "    total_prevalence = sum(get_bigram_prevalence(' '.join(bigram)) for bigram in bigram_sequence)\n",
    "    return total_prevalence\n",
    "\n",
    "\n",
    "def get_text_average_prevalence(text):\n",
    "    \"\"\"Calculate the average prevalence factor for all words in the text.\"\"\"\n",
    "    text = clean_text(text)  # Clean the text\n",
    "    words = word_tokenize(text)  # Clean the text\n",
    "    total_prevalence = sum(get_prevalence_word(word) for word in words)\n",
    "    return total_prevalence / len(words)\n",
    "\n",
    "def get_text_median_prevalence(text):\n",
    "    text = clean_text(text)\n",
    "    words = text.split()\n",
    "    prevalences = []\n",
    "    for word in words:\n",
    "        if (prevalence_dict.get(word) is not None):\n",
    "            prevalences.append(prevalence_dict[word])\n",
    "    return np.median(prevalences)\n",
    "\n",
    "def get_text_percentage_of_words_in_prevalence_table(text):\n",
    "    \"\"\"Calculate the percentage of words in the text that are in the prevalence table.\"\"\"\n",
    "    text = clean_text(text)  # Clean the text\n",
    "    words = word_tokenize(text)  # Tokenize the text into words\n",
    "    words_in_table = sum(word in prevalence_dict for word in words)\n",
    "    return words_in_table / len(words)\n",
    "\n",
    "def get_text_bigram_prevalence_std(text):\n",
    "    \"\"\"Calculate the standard deviation of the prevalence factors for all bigrams in the text.\"\"\"\n",
    "    text = clean_text(text)  # Clean the text\n",
    "    words = text.split()  # Tokenize the text into words\n",
    "    bigram_sequence = list(bigrams(words))  # Create bigrams from the words\n",
    "    bigram_list = [' '.join(bigram) for bigram in bigram_sequence]  # Rename variable here\n",
    "    prevalences = []\n",
    "    for bigram in bigram_list:  # Use the renamed variable\n",
    "        if two_word_prevalence_table.get(bigram) is not None:\n",
    "            prevalences.append(two_word_prevalence_table[bigram])\n",
    "    if len(prevalences) == 0:\n",
    "        return 0\n",
    "    return np.std(prevalences)\n",
    "\n",
    "\n",
    "def get_text_bigram_prevalence_mean(text):\n",
    "    \"\"\"Calculate the mean of the prevalence factors for all bigrams in the text.\"\"\"\n",
    "    text = clean_text(text)  # Clean the text\n",
    "    words = word_tokenize(text)  # Tokenize the text into words\n",
    "    bigram_sequence = list(bigrams(words))  # Create bigrams from the words\n",
    "    prevalences = [get_bigram_prevalence(' '.join(bigram)) for bigram in bigram_sequence]\n",
    "    return np.mean(prevalences)\n",
    "\n",
    "def get_text_bigram_prevalence_median(text):\n",
    "    \"\"\"Calculate the median of the prevalence factors for all bigrams in the text.\"\"\"\n",
    "    text = clean_text(text)  # Clean the text\n",
    "    words = text.split()  # Tokenize the text into words\n",
    "    bigram_sequence = list(bigrams(words))  # Create bigrams from the words\n",
    "    bigram_list = [' '.join(bigram) for bigram in bigram_sequence]  # Rename variable here\n",
    "    prevalences = []\n",
    "    for bigram in bigram_list:  # Use the renamed variable\n",
    "        if two_word_prevalence_table.get(bigram) is not None:\n",
    "            prevalences.append(two_word_prevalence_table[bigram])\n",
    "    if len(prevalences) == 0:\n",
    "        return 0\n",
    "    return np.median(prevalences)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean the text for analysis.\"\"\"\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "def get_bigram_prevalence(bigram):\n",
    "    \"\"\"Get the prevalence factor for a bigram.\"\"\"\n",
    "    bigram = tuple(bigram.split())  # Ensure the bigram is in tuple format\n",
    "    return two_word_prevalence_dict.get(' '.join(bigram), 0)\n",
    "\n",
    "def get_text_median_complexity(text):\n",
    "    text = str(text)\n",
    "    words = complex.clean_text(text)\n",
    "    complexities = [calculate_complexity(word) for word in words]\n",
    "    return np.median(complexities)\n",
    "\n",
    "def get_prevalence_word(word):\n",
    "    word = str(word)\n",
    "    word = word.lower()\n",
    "    if word in prevalence_dict:\n",
    "        return prevalence_dict[word]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_prevalence_text(text):\n",
    "    text = str(text)\n",
    "    words = text.split()\n",
    "    prevalence = 0\n",
    "    for word in words:\n",
    "        word = complex.clean_word(word)\n",
    "        prevalence += get_prevalence_word(word)\n",
    "    return prevalence\n",
    "\n",
    "def get_text_prevalence_std(text):\n",
    "    text = str(text)\n",
    "    words = text.split()\n",
    "    prevalences = []\n",
    "    for word in words:\n",
    "        if (prevalence_dict.get(word) is not None):\n",
    "            prevalences.append(prevalence_dict[word])\n",
    "    if len(prevalences) == 0:\n",
    "        return 0\n",
    "    return np.std(prevalences)\n",
    "\n",
    "def get_text_number_percentage(text):\n",
    "    words = complex.clean_text(text)\n",
    "    total_words = len(words)\n",
    "    numeric_words = sum(word.replace(',', '').replace('.', '').isdigit() for word in words)\n",
    "    if total_words > 0:\n",
    "        percentage = (numeric_words / total_words) \n",
    "    else:\n",
    "        percentage = 0\n",
    "    return percentage\n",
    "\n",
    "def get_text_variance(text):\n",
    "    text = str(text)\n",
    "    words = complex.clean_text(text)\n",
    "    complexities = []\n",
    "    for word in words:\n",
    "        complexity = calculate_complexity(word) * len( word.split())\n",
    "        complexities.append(complexity)\n",
    "    return np.std(complexities)\n",
    "\n",
    "def get_text_sentence_std(text):\n",
    "    text = str(text)\n",
    "    sentences = split_into_sentences(text)\n",
    "    lengths = [len(sentence.split()) for sentence in sentences]\n",
    "    std = np.std(lengths)\n",
    "    return std\n",
    "\n",
    "def get_paragraph_std(text):\n",
    "    text = str(text)\n",
    "    paragraphs = split_into_paragraphs(text)\n",
    "    lengths = [len(paragraph.split()) for paragraph in paragraphs]\n",
    "    std = np.std(lengths)\n",
    "    return std\n",
    "\n",
    "def get_text_length(text):\n",
    "    text = str(text)\n",
    "    return len(text.split())\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = str(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "def get_average_paragraph_length(text):\n",
    "    text = str(text)\n",
    "    paragraphs = split_into_paragraphs(text)\n",
    "    lengths = [len(paragraph.split()) for paragraph in paragraphs]\n",
    "    return np.mean(lengths)\n",
    "\n",
    "def split_into_paragraphs(text):\n",
    "    \"\"\"\n",
    "    Splits the input text into paragraphs and returns a list of paragraphs.\n",
    "    Accounts for paragraphs split by one or more newlines.\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    # Replace double newlines with a unique marker, then split on single newlines\n",
    "    unique_marker = '\\x02'  # Using ASCII Start of Text character as unlikely to appear in text\n",
    "    text_with_markers = text.replace('\\n\\n', unique_marker)\n",
    "    potential_paragraphs = text_with_markers.split('\\n')\n",
    "    \n",
    "    # Split again on the unique marker to identify paragraphs split by double newlines\n",
    "    paragraphs = []\n",
    "    for para in potential_paragraphs:\n",
    "        if unique_marker in para:\n",
    "            paragraphs.extend(para.split(unique_marker))\n",
    "        else:\n",
    "            paragraphs.append(para)\n",
    "    \n",
    "    # Filter out any empty paragraphs that may result from multiple newlines\n",
    "    paragraphs = [para.strip() for para in paragraphs if para.strip()]\n",
    "    return paragraphs\n",
    "\n",
    "def get_text_length(text):\n",
    "    text = str(text)\n",
    "    return len(text.split())\n",
    "\n",
    "def percentage_of_capitalized_words(text):\n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    capitalized_non_starter_count = 0\n",
    "    total_words_count = 0\n",
    "\n",
    "    # Iterate over each sentence\n",
    "    for sentence in sentences:\n",
    "        # Split the sentence into words\n",
    "        words = sentence.split()\n",
    "        # Exclude the first word of a sentence from the count\n",
    "        words_to_check = words[1:] if len(words) > 0 else []\n",
    "        # Count the number of capitalized words that are not sentence starters\n",
    "        capitalized_non_starter_count += sum(1 for word in words_to_check if word.istitle())\n",
    "        total_words_count += len(words_to_check)\n",
    "\n",
    "    # Calculate the percentage of capitalized words that are not sentence starters\n",
    "    if total_words_count == 0:  # Avoid division by zero\n",
    "        return 0\n",
    "    percentage = (capitalized_non_starter_count / total_words_count) * 100\n",
    "    return percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path = \"megaset4.csv\"\n",
    "path = \"test_essays.csv\"\n",
    "dataset = pd.read_csv(path)\n",
    "\n",
    "# dataset['text'] = dataset['text'].astype(str)\n",
    "\n",
    "\n",
    "# dataset['fivegram_prevalence'] = dataset['text'].apply(get_text_fivegram_prevalence)\n",
    "# print('fivegram_prevalence done')\n",
    "# dataset['percentage_capitalized'] = dataset['text'].apply(percentage_of_capitalized_words)\n",
    "# print('percentage_capitalized done')\n",
    "\n",
    "# dataset['fourgram_prevalence'] = dataset['text'].apply(get_text_fourgram_prevalence)\n",
    "# print('fourgram_prevalence done')\n",
    "\n",
    "# dataset['average_prevalence'] = dataset['text'].apply(get_text_average_prevalence)\n",
    "# print('average_prevalence done')\n",
    "\n",
    "# dataset['median_prevalence'] = dataset['text'].apply(get_text_median_prevalence)\n",
    "# print('median_prevalence done')\n",
    "\n",
    "# dataset['prevalence_std'] = dataset['text'].apply(get_text_prevalence_std)\n",
    "# print('prevalence_std done')\n",
    "\n",
    "# dataset['bigram_prevalence_std'] = dataset['text'].apply(get_text_bigram_prevalence_std)\n",
    "# print('bigram_prevalence_std done')\n",
    "# dataset['bigram_prevalence_mean'] = dataset['text'].apply(get_text_bigram_prevalence_mean)\n",
    "# print('bigram_prevalence_mean done')\n",
    "# dataset['bigram_prevalence_median'] = dataset['text'].apply(get_text_bigram_prevalence_median)\n",
    "# print('bigram_prevalence_median done')\n",
    "# dataset['weighted_prevalence'] = dataset['text'].apply(get_text_weighted_prevalence)\n",
    "# print('weighted_prevalence done')\n",
    "\n",
    "# dataset['median_complexity'] = dataset['text'].apply(get_text_median_complexity)\n",
    "# print('median_complexity done')\n",
    "\n",
    "# dataset['paragraph_std'] = dataset['text'].apply(get_paragraph_std)\n",
    "# print('paragraph_std done')\n",
    "\n",
    "# dataset['average_paragraph_length'] = dataset['text'].apply(get_average_paragraph_length)\n",
    "# print('average_paragraph_length done')\n",
    "# dataset['complexity'] = dataset['text'].apply(calculate_complexity)\n",
    "# print('complexity done')\n",
    "# dataset['number_percentage'] = dataset['text'].apply(get_text_number_percentage)\n",
    "# print('number_percentage done')\n",
    "# dataset['readability'] = dataset['text'].apply(textstat.flesch_reading_ease)\n",
    "# print('readability done')\n",
    "\n",
    "dataset['prevalence'] = dataset['text'].apply(get_prevalence_text)\n",
    "print('prevalence done')\n",
    "dataset['bigram_prevalence'] = dataset['text'].apply(get_text_bigram_prevalence)\n",
    "print('bigram_prevalence done')\n",
    "# dataset['trigram_prevalence'] = dataset['text'].apply(get_text_trigram_prevalence)\n",
    "# print('trigram_prevalence done')\n",
    "dataset['length'] = dataset['text'].apply(get_text_length)\n",
    "print('length done')\n",
    "dataset['variance'] = dataset['text'].apply(get_text_variance)\n",
    "print('variance done')\n",
    "# dataset['sentence_std'] = dataset['text'].apply(get_text_sentence_std)\n",
    "# print('sentence_std done')\n",
    "# dataset['percentage_of_words_in_prevalence_table'] = dataset['text'].apply(get_text_percentage_of_words_in_prevalence_table)\n",
    "# print('percentage_of_words_in_prevalence_table done')\n",
    "\n",
    "dataset.to_csv(path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"human_expert_essays.csv\"\n",
    "path = \"human.csv\"\n",
    "path = \"Essays/ai_generated_essays_llm_detect_kaggle.csv\"\n",
    "path = \"undetectable.csv\"\n",
    "path = \"final_test2.csv\"\n",
    "dataset = pd.read_csv(path)\n",
    "\n",
    "# dataset.info()\n",
    "\n",
    "# from object to string\n",
    "# convert text to string\n",
    "# dataset['text'] = dataset['text'].astype(str)\n",
    "\n",
    "\n",
    "dataset['fivegram_prevalence'] = dataset['text'].apply(get_text_fivegram_prevalence)\n",
    "print('fivegram_prevalence done')\n",
    "# dataset['percentage_capitalized'] = dataset['text'].apply(percentage_of_capitalized_words)\n",
    "# print('percentage_capitalized done')\n",
    "# dataset['fourgram_prevalence'] = dataset['text'].apply(get_text_fourgram_prevalence)\n",
    "# print('fourgram_prevalence done')\n",
    "# dataset['average_prevalence'] = dataset['text'].apply(get_text_average_prevalence)\n",
    "# print('average_prevalence done')\n",
    "# dataset['median_prevalence'] = dataset['text'].apply(get_text_median_prevalence)\n",
    "# print('median_prevalence done')\n",
    "# dataset['prevalence_std'] = dataset['text'].apply(get_text_prevalence_std)\n",
    "# print('prevalence_std done')\n",
    "# dataset['bigram_prevalence_std'] = dataset['text'].apply(get_text_bigram_prevalence_std)\n",
    "# print('bigram_prevalence_std done')\n",
    "# dataset['bigram_prevalence_mean'] = dataset['text'].apply(get_text_bigram_prevalence_mean)\n",
    "# print('bigram_prevalence_mean done')\n",
    "# dataset['bigram_prevalence_median'] = dataset['text'].apply(get_text_bigram_prevalence_median)\n",
    "# print('bigram_prevalence_median done')\n",
    "# dataset['weighted_prevalence'] = dataset['text'].apply(get_text_weighted_prevalence)\n",
    "# print('weighted_prevalence done')\n",
    "# dataset['median_complexity'] = dataset['text'].apply(get_text_median_complexity)\n",
    "# print('median_complexity done')\n",
    "# dataset['paragraph_std'] = dataset['text'].apply(get_paragraph_std)\n",
    "# print('paragraph_std done')\n",
    "# dataset['average_paragraph_length'] = dataset['text'].apply(get_average_paragraph_length)\n",
    "# print('average_paragraph_length done')\n",
    "# dataset['prevalence'] = dataset['text'].apply(get_prevalence_text)\n",
    "# dataset['complexity'] = dataset['text'].apply(calculate_complexity)\n",
    "# print('complexity done')\n",
    "# dataset['number_percentage'] = dataset['text'].apply(get_text_number_percentage)\n",
    "# print('number_percentage done')\n",
    "# dataset['readability'] = dataset['text'].apply(textstat.flesch_reading_ease)\n",
    "# print('readability done')\n",
    "# dataset['bigram_prevalence'] = dataset['text'].apply(get_text_bigram_prevalence)\n",
    "# print('bigram_prevalence done')\n",
    "# dataset['trigram_prevalence'] = dataset['text'].apply(get_text_trigram_prevalence)\n",
    "# print('trigram_prevalence done')\n",
    "# dataset['length'] = dataset['text'].apply(get_text_length)\n",
    "# print('length done')\n",
    "# dataset['variance'] = dataset['text'].apply(get_text_variance)\n",
    "# print('variance done')\n",
    "# dataset['sentence_std'] = dataset['text'].apply(get_text_sentence_std)\n",
    "# print('sentence_std done')\n",
    "# dataset['percentage_of_words_in_prevalence_table'] = dataset['text'].apply(get_text_percentage_of_words_in_prevalence_table)\n",
    "# print('percentage_of_words_in_prevalence_table done')\n",
    "\n",
    "dataset.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained and Tested with itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Assuming dataset is already loaded and contains the 'complexity', 'Prevalence', and 'generated' columns\n",
    "\n",
    "# Prepare the features and target\n",
    "\n",
    "X = dataset[x_features]  # Features\n",
    "y = dataset['generated']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Initialize KNN classifier\n",
    "# Number of neighbors can be tuned; starting with 5\n",
    "knn = KNeighborsClassifier(n_neighbors=51)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Overall accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate the confusion matrix to get false positive and false negative rates\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "false_positive_rate = fp / (fp + tn)\n",
    "false_negative_rate = fn / (fn + tp)\n",
    "\n",
    "print(f\"False 0 rate (False Positive Rate): {false_positive_rate * 100:.2f}%\")\n",
    "print(f\"False 1 rate (False Negative Rate): {false_negative_rate * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-standardized KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "path_train = \"megaset4.csv\"\n",
    "train_data = pd.read_csv(path_train)\n",
    "\n",
    "# Load the testing dataset\n",
    "path_test = \"final_test2.csv\"\n",
    "test_data = pd.read_csv(path_test)\n",
    "\n",
    "\n",
    "# Prepare the features and target for the training data\n",
    "X_train = train_data[x_features]  # Features\n",
    "y_train = train_data['generated']  # Target variable\n",
    "\n",
    "# Prepare the features and target for the testing data\n",
    "X_test = test_data[x_features]  # Features\n",
    "y_test = test_data['generated']  # Target variable\n",
    "\n",
    "\n",
    "# Initialize KNN classifier with a certain number of neighbors, e.g., 5\n",
    "knn = KNeighborsClassifier(n_neighbors=51)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "knn.fit(X_train, y_train)\n",
    " \n",
    "# X_test = pd.read_csv('undetectable.csv')\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy on the testing data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Overall accuracy on the test set: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate the confusion matrix to get false positive and false negative rates\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Calculate rates\n",
    "false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "# Print the rates\n",
    "print(f\"False Positive Rate: {false_positive_rate * 100:.2f}%\")\n",
    "print(f\"False Negative Rate: {false_negative_rate * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardized KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "path_train = \"megaset4.csv\"\n",
    "train_data = pd.read_csv(path_train)\n",
    "\n",
    "# Load the testing dataset\n",
    "path_test = \"human.csv\"\n",
    "path_test = \"human_expert_essays.csv\"\n",
    "path_test = \"Essays/ai_generated_essays_llm_detect_kaggle.csv\"\n",
    "path_test = \"final_test2.csv\"\n",
    "\n",
    "test_data = pd.read_csv(path_test).sample(10000)\n",
    "\n",
    "# drop na rows\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare the features and target for the training data\n",
    "X_train = train_data[x_features]  # Features\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform the training data\n",
    "y_train = train_data['generated']  # Target variable\n",
    "\n",
    "# Prepare the features and target for the testing data\n",
    "X_test = test_data[x_features]  # Features\n",
    "X_test_scaled = scaler.transform(X_test)  # Transform the testing data using the same scaler\n",
    "y_test = test_data['generated']  # Target variable\n",
    "\n",
    "# Initialize KNN classifier with a certain number of neighbors, e.g., 5\n",
    "knn = KNeighborsClassifier(n_neighbors=51)\n",
    "\n",
    "# Train the classifier on the scaled training data\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the scaled testing data\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the accuracy on the testing data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Overall accuracy on the test set: {accuracy * 100:.4f}%\")\n",
    "\n",
    "# Calculate the confusion matrix to get false positive and false negative rates\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Calculate rates\n",
    "false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "# Print the rates\n",
    "print(f\"False Positive Rate: {false_positive_rate * 100:.4f}%\")\n",
    "print(f\"False Negative Rate: {false_negative_rate * 100:.4f}%\")\n",
    "print(f\"Average error rate: {(false_positive_rate*100+ false_negative_rate*100) / 2 :.4f}%\")\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Use the predict_proba method\n",
    "y_proba = knn.predict_proba(X_test_scaled)\n",
    "\n",
    "# Choose a custom threshold\n",
    "threshold = 0.5  # Lowering the threshold may increase the FPR and decrease the FNR\n",
    "\n",
    "# Apply custom threshold to get new predictions\n",
    "y_pred_custom = (y_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "# Recalculate the metrics with the new predictions\n",
    "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
    "conf_matrix_custom = confusion_matrix(y_test, y_pred_custom)\n",
    "tn_custom, fp_custom, fn_custom, tp_custom = conf_matrix_custom.ravel()\n",
    "\n",
    "# Recalculate rates\n",
    "false_positive_rate_custom = fp_custom / (fp_custom + tn_custom) if (fp_custom + tn_custom) > 0 else 0\n",
    "false_negative_rate_custom = fn_custom / (fn_custom + tp_custom) if (fn_custom + tp_custom) > 0 else 0\n",
    "\n",
    "# Print the new rates\n",
    "print(f\"Custom Threshold: {threshold}\")\n",
    "print(f\"Overall accuracy on the test set with custom threshold: {accuracy_custom * 100:.4f}%\")\n",
    "print(f\"False Positive Rate with custom threshold: {false_positive_rate_custom * 100:.4f}%\")\n",
    "print(f\"False Negative Rate with custom threshold: {false_negative_rate_custom * 100:.4f}%\")\n",
    "print(f\"Average error rate with custom threshold: {(false_positive_rate_custom*100 + false_negative_rate_custom*100) / 2 :.4f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prevalence-factor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 57.3556%\n",
      "False Positive Rate: 6.8120%\n",
      "False Negative Rate: 52.6677%\n",
      "Average error rate: 29.7398%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'final_test2.csv' is the correct path to your test dataset\n",
    "test_data = pd.read_csv('final_test2.csv')\n",
    "test_data = pd.read_csv('test_essays.csv')\n",
    "# test_data = pd.read_csv('undetectable.csv')\n",
    "\n",
    "# Assign 1 if 'prevalence' > 0, else 0, for each row in the DataFrame\n",
    "# test_data['prediction'] = (test_data['prevalence'] + test_data['bigram_prevalence'] + test_data['trigram_prevalence'] + \n",
    "#                            test_data['fourgram_prevalence'] + test_data['fivegram_prevalence']> 0).astype(int)\n",
    "test_data['prediction'] = (test_data['prevalence'] + test_data['bigram_prevalence']> 0).astype(int)\n",
    "\n",
    "\n",
    "# Calculate and print the overall accuracy\n",
    "accuracy = accuracy_score(test_data['generated'], test_data['prediction'])\n",
    "print(f\"Overall accuracy: {accuracy * 100:.4f}%\")\n",
    "\n",
    "# Calculate the confusion matrix to get false positive and false negative rates\n",
    "conf_matrix = confusion_matrix(test_data['generated'], test_data['prediction'])\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Calculate rates\n",
    "false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "# Print the rates\n",
    "print(f\"False Positive Rate: {false_positive_rate * 100:.4f}%\")\n",
    "print(f\"False Negative Rate: {false_negative_rate * 100:.4f}%\")\n",
    "print(f\"Average error rate: {(false_positive_rate*100+ false_negative_rate*100) / 2 :.4f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardized RBF Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "path_train = \"megaset4.csv\"\n",
    "train_data = pd.read_csv(path_train)\n",
    "\n",
    "# Load the testing dataset\n",
    "path_test = \"final_test2.csv\"\n",
    "test_data = pd.read_csv(path_test).sample(10000)\n",
    "\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare the features and target for the training data\n",
    "X_train = train_data[x_features]  # Features\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform the training data\n",
    "y_train = train_data['generated']  # Target variable\n",
    "\n",
    "# Prepare the features and target for the testing data\n",
    "X_test = test_data[x_features]  # Features\n",
    "X_test_scaled = scaler.transform(X_test)  # Transform the testing data using the same scaler\n",
    "y_test = test_data['generated']  # Target variable\n",
    "\n",
    "# Initialize Gaussian SVM classifier\n",
    "\n",
    "# svm_clf = SVC(kernel='rbf', C=1, gamma='scale')  # 'scale' is the default value for gamma\n",
    "\n",
    "svm_clf = SVC(kernel='rbf', C=1, gamma='scale', probability=True)\n",
    "\n",
    "# Train the classifier on the scaled training data\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the scaled testing data\n",
    "y_pred = svm_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the accuracy on the testing data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Overall accuracy on the test set: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate the confusion matrix to get false positive and false negative rates\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Calculate rates\n",
    "false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "# Print the rates\n",
    "print(f\"False Positive Rate: {false_positive_rate * 100:.2f}%\")\n",
    "print(f\"False Negative Rate: {false_negative_rate * 100:.2f}%\")\n",
    "print(f\"Average error rate: {(false_positive_rate*100+ false_negative_rate*100) / 2 :.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "Best:\n",
    "\n",
    "x_features = ['complexity', 'prevalence', 'bigram_prevalence', 'trigram_prevalence', \n",
    "              'sentence_std', 'readability', 'average_prevalence', 'median_prevalence', \n",
    "              'prevalence_std', 'variance', 'number_percentage', 'bigram_prevalence_std', \n",
    "              'bigram_prevalence_mean', 'bigram_prevalence_median', 'paragraph_std', 'length']\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(12,12), activation='relu', solver='adam', max_iter=400, random_state=12) \n",
    "\n",
    "1.26\n",
    "\n",
    "\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.13524513\n",
      "Iteration 2, loss = 0.04444581\n",
      "Iteration 3, loss = 0.03902259\n",
      "Iteration 4, loss = 0.03741978\n",
      "Iteration 5, loss = 0.03657398\n",
      "Iteration 6, loss = 0.03595962\n",
      "Iteration 7, loss = 0.03557124\n",
      "Iteration 8, loss = 0.03511527\n",
      "Iteration 9, loss = 0.03502677\n",
      "Iteration 10, loss = 0.03446367\n",
      "Iteration 11, loss = 0.03442558\n",
      "Iteration 12, loss = 0.03423272\n",
      "Iteration 13, loss = 0.03392674\n",
      "Iteration 14, loss = 0.03386512\n",
      "Iteration 15, loss = 0.03358167\n",
      "Iteration 16, loss = 0.03353267\n",
      "Iteration 17, loss = 0.03330155\n",
      "Iteration 18, loss = 0.03312898\n",
      "Iteration 19, loss = 0.03293316\n",
      "Iteration 20, loss = 0.03296112\n",
      "Iteration 21, loss = 0.03278027\n",
      "Iteration 22, loss = 0.03270985\n",
      "Iteration 23, loss = 0.03261398\n",
      "Iteration 24, loss = 0.03246170\n",
      "Iteration 25, loss = 0.03220793\n",
      "Iteration 26, loss = 0.03217191\n",
      "Iteration 27, loss = 0.03200358\n",
      "Iteration 28, loss = 0.03188274\n",
      "Iteration 29, loss = 0.03167471\n",
      "Iteration 30, loss = 0.03149820\n",
      "Iteration 31, loss = 0.03155829\n",
      "Iteration 32, loss = 0.03123593\n",
      "Iteration 33, loss = 0.03133260\n",
      "Iteration 34, loss = 0.03115599\n",
      "Iteration 35, loss = 0.03119829\n",
      "Iteration 36, loss = 0.03101107\n",
      "Iteration 37, loss = 0.03092991\n",
      "Iteration 38, loss = 0.03070035\n",
      "Iteration 39, loss = 0.03076226\n",
      "Iteration 40, loss = 0.03063049\n",
      "Iteration 41, loss = 0.03070984\n",
      "Iteration 42, loss = 0.03066092\n",
      "Iteration 43, loss = 0.03058448\n",
      "Iteration 44, loss = 0.03044537\n",
      "Iteration 45, loss = 0.03036099\n",
      "Iteration 46, loss = 0.03032144\n",
      "Iteration 47, loss = 0.03018438\n",
      "Iteration 48, loss = 0.03022237\n",
      "Iteration 49, loss = 0.03014120\n",
      "Iteration 50, loss = 0.03003059\n",
      "Iteration 51, loss = 0.03021436\n",
      "Iteration 52, loss = 0.03004210\n",
      "Iteration 53, loss = 0.03003844\n",
      "Iteration 54, loss = 0.02999614\n",
      "Iteration 55, loss = 0.02992354\n",
      "Iteration 56, loss = 0.02990673\n",
      "Iteration 57, loss = 0.02988686\n",
      "Iteration 58, loss = 0.02984418\n",
      "Iteration 59, loss = 0.02975993\n",
      "Iteration 60, loss = 0.02974715\n",
      "Iteration 61, loss = 0.02974401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy on the training set: 99.00%\n",
      "Accuracy on the test set: 98.78%\n",
      "False Positive Rate on test data: 0.8549%\n",
      "False Negative Rate on test data: 1.9408%\n",
      "Average error rate on test data: 1.3979%\n",
      "Score: 168.49\n",
      "Confusion Matrix for the test data:\n",
      "[[55316   477]\n",
      " [  552 27890]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "path_train = \"train_essays.csv\"\n",
    "path_train = \"megaset4.csv\"\n",
    "train_data = pd.read_csv(path_train)\n",
    "\n",
    "# train_data_dropped = train_data.drop(train_data[train_data['generated'] == 1].sample(n=1).index)\n",
    "train_data = train_data[train_data['text'].apply(lambda x: get_text_length(x) >= 0 and get_text_length(x) <= 5000)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_data = pd.concat([train_data[train_data['generated'] == 0].sample(n=train_data['generated'].value_counts().min(), random_state=42), train_data[train_data['generated'] == 1].sample(n=train_data['generated'].value_counts().min(), random_state=42)])\n",
    "\n",
    "\n",
    "# Load the testing dataset\n",
    "path_test = \"Essays/ai_generated_essays_llm_detect_kaggle.csv\"\n",
    "path_test = \"undetectable.csv\"\n",
    "path_test = \"test_essays.csv\"\n",
    "path_test = \"final_test2.csv\"\n",
    "test_data = pd.read_csv(path_test)\n",
    "test_data = test_data[test_data['text'].apply(lambda x: get_text_length(x) >= 00 and get_text_length(x) <= 10000)]\n",
    "\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    " \n",
    "x_features = ['complexity', 'prevalence', 'bigram_prevalence', 'trigram_prevalence', \n",
    "              'sentence_std', 'readability', 'average_prevalence', 'median_prevalence', \n",
    "              'prevalence_std', 'variance', 'number_percentage', 'bigram_prevalence_std', \n",
    "              'bigram_prevalence_mean', 'bigram_prevalence_median']\n",
    "\n",
    "\n",
    "x_features = [ 'complexity', 'prevalence', 'bigram_prevalence', 'trigram_prevalence', \n",
    "              'sentence_std',  'average_prevalence', 'median_prevalence', \n",
    "              'prevalence_std', 'variance', 'number_percentage', 'paragraph_std', 'length']\n",
    "\n",
    "x_features = ['complexity', 'prevalence', 'bigram_prevalence', 'trigram_prevalence', \n",
    "              'sentence_std', 'readability', 'average_prevalence', 'median_prevalence', \n",
    "              'prevalence_std', 'variance', 'number_percentage',  'paragraph_std', 'median_complexity',\n",
    "]\n",
    "\n",
    "x_features = ['complexity', 'prevalence', 'bigram_prevalence', 'trigram_prevalence', \n",
    "              'sentence_std', 'readability', 'average_prevalence', 'median_prevalence', \n",
    "              'prevalence_std', 'variance', 'number_percentage', 'bigram_prevalence_std', \n",
    "              'bigram_prevalence_mean', 'bigram_prevalence_median', 'paragraph_std', 'length']\n",
    "\n",
    "\n",
    "x_features = ['complexity', 'readability', 'variance', 'sentence_std', 'prevalence', 'average_prevalence', 'median_prevalence', 'bigram_prevalence',\n",
    "              'paragraph_std', 'length', 'number_percentage', 'prevalence_std', 'bigram_prevalence_std', 'bigram_prevalence_mean', 'bigram_prevalence_median',\n",
    "              'percentage_of_words_in_prevalence_table', 'median_complexity','trigram_prevalence']\n",
    "              \n",
    "x_features = ['prevalence', 'bigram_prevalence', \n",
    "              'prevalence_std', 'complexity', 'length','trigram_prevalence']\n",
    "\n",
    "x_features = ['prevalence', 'bigram_prevalence', 'trigram_prevalence', 'fourgram_prevalence', 'variance', 'length', 'median_prevalence', 'complexity']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare the features and target for the training data\n",
    "X_train = train_data[x_features]\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train = train_data['generated']\n",
    "\n",
    "# Prepare the features and target for the testing data\n",
    "X_test = test_data[x_features]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test = test_data['generated']\n",
    "\n",
    "# Initialize MLPClassifier with a specified architecture\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(25,25), activation='relu', \n",
    "                        solver='adam', max_iter=4000, random_state=12, verbose=True, tol=0.0001)  \n",
    "\n",
    "\n",
    "# Train the classifier on the scaled training data\n",
    "mlp_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Make predictions on the scaled testing data\n",
    "# y_pred_test = mlp_clf.predict(X_test_scaled)\n",
    "# # Make predictions on the scaled training data for overfitting check\n",
    "# y_pred_train = mlp_clf.predict(X_train_scaled)\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "# Get prediction probabilities for the scaled testing data\n",
    "y_pred_proba_test = mlp_clf.predict_proba(X_test_scaled)[:, 1]  # Probability of the positive class\n",
    "# Convert probabilities to binary outcomes based on the threshold\n",
    "y_pred_test = (y_pred_proba_test >= threshold).astype(int)\n",
    "\n",
    "# Get prediction probabilities for the scaled training data\n",
    "y_pred_proba_train = mlp_clf.predict_proba(X_train_scaled)[:, 1]  # Probability of the positive class\n",
    "# Convert probabilities to binary outcomes based on the threshold\n",
    "y_pred_train = (y_pred_proba_train >= threshold).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the accuracy on the testing data\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "# Evaluate the accuracy on the training data\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Output the accuracies\n",
    "print(f\"Accuracy on the training set: {accuracy_train * 100:.2f}%\")\n",
    "print(f\"Accuracy on the test set: {accuracy_test * 100:.2f}%\")\n",
    "\n",
    "# If the accuracy on the training set is significantly higher than on the test set,\n",
    "# it may indicate overfitting.\n",
    "\n",
    "# Calculate the confusion matrix for test data to get false positive and false negative rates\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = conf_matrix_test.ravel()\n",
    "\n",
    "# Calculate rates\n",
    "false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "# Print the rates\n",
    "print(f\"False Positive Rate on test data: {false_positive_rate * 100:.4f}%\")\n",
    "print(f\"False Negative Rate on test data: {false_negative_rate * 100:.4f}%\")\n",
    "print(f\"Average error rate on test data: {(false_positive_rate*100 + false_negative_rate*100) / 2 :.4f}%\")\n",
    "\n",
    "score = 1 / false_negative_rate + 1 / false_positive_rate\n",
    "print(f\"Score: {score:.2f}\")\n",
    "\n",
    "# Print the confusion matrix for the test data\n",
    "print(\"Confusion Matrix for the test data:\")\n",
    "print(conf_matrix_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  1\n",
      "Features: [-12808.140878794833, -4053.6793170306305, -484.9661406942898, 625.1712575531878, 22248.590292647506, 6408, -1.016281438202946]\n",
      "Scaled Features: [[-5.46844835 -1.14440575 -0.51604874 -0.28329656  1.18392423 13.18368489\n",
      "  -0.70669057]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 1.6605755220559422e-11%\n",
      "Index:  2\n",
      "Features: [-4691.779076077079, 2884.082882912085, 2360.771229856527, 1061.134394741611, 21414.527789215183, 6856, 1.0216708560153416]\n",
      "Scaled Features: [[-1.9822257   0.35188094  0.04774961 -0.15356701  0.79451609 14.17413678\n",
      "   0.87446287]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 1.544028223173057e-16%\n",
      "Index:  3\n",
      "Features: [-1542.7132900745994, -1931.2383014200793, 300.3099655288885, 257.61573943797185, 20527.8136592938, 3451, -1.1282367307056391]\n",
      "Scaled Features: [[-0.62960679 -0.68665293 -0.3604696  -0.39267006  0.38052589  6.64626024\n",
      "  -0.79355153]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 1.1365966012386766e-08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  4\n",
      "Features: [-3663.9186547272866, -2821.3925225591684, -662.0823412919108, 21.024077482313828, 19244.224448780817, 1785, -1.2172971957531755]\n",
      "Scaled Features: [[-1.54072859 -0.87863499 -0.55113906 -0.46307264 -0.21875785  2.96301726\n",
      "  -0.86264945]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 0.001290113902777759%\n",
      "Index:  5\n",
      "Features: [-13943.613036347511, -3245.3636739501617, -1328.8871879376788, -648.060341919317, 20866.554375052463, 2762, -1.7102337843039426]\n",
      "Scaled Features: [[-5.95616795 -0.97007404 -0.68324664 -0.66217209  0.53867757  5.12299829\n",
      "  -1.24509627]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 2.510239843376181e-13%\n",
      "Index:  6\n",
      "Features: [-5688.815270794946, -2199.394987049079, -877.7091003486378, -173.51923747916678, 20185.20629411792, 1502, -1.732188690249852]\n",
      "Scaled Features: [[-2.41048287 -0.74448703 -0.5938591  -0.52096289  0.22056893  2.33735234\n",
      "  -1.26213008]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 0.00015699489460628045%\n",
      "Index:  7\n",
      "Features: [-532.2089078506299, -901.6781871436559, -445.291346088962, 20.353738301556657, 18415.386230652366, 916, -1.1282367307056391]\n",
      "Scaled Features: [[-0.19556462 -0.4646048  -0.50818836 -0.46327211 -0.60572687  1.04180589\n",
      "  -0.79355153]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 0.020688741177796087%\n",
      "Index:  8\n",
      "Features: [-443.6841368204636, -862.0464547605264, -154.44279463377316, 117.84606318269334, 20737.776642180437, 483, -1.2172971957531755]\n",
      "Scaled Features: [[-0.15754056 -0.45605731 -0.45056536 -0.43426132  0.47855367  0.08451645\n",
      "  -0.86264945]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 4.208392788768956%\n",
      "Index:  9\n",
      "Features: [-488.0164788500733, -241.67522412410358, -91.93213360172304, -21.76028062581052, 19251.059480354037, 312, -1.2531714572745878]\n",
      "Scaled Features: [[-0.17658264 -0.3222601  -0.43818073 -0.47580398 -0.2155667  -0.2935355\n",
      "  -0.89048264]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 38.26053858483703%\n",
      "Index:  10\n",
      "Features: [-2420.3488125084887, -2535.968986504065, -664.2709779847269, -126.42184886823175, 20293.871383103655, 859, -1.3686765502199685]\n",
      "Scaled Features: [[-1.00657777 -0.8170769  -0.55157267 -0.50694812  0.27130262  0.91578857\n",
      "  -0.98009773]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 0.011185380970399278%\n",
      "Index:  11\n",
      "Features: [-221.30956585128075, -90.98003132145891, -140.25342329255028, -87.04230292720003, 20730.840962822585, 242, -1.2394521979845543]\n",
      "Scaled Features: [[-0.06202396 -0.28975925 -0.44775415 -0.49522995  0.47531553 -0.44829361\n",
      "  -0.8798385 ]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 28.904305282881438%\n",
      "Index:  12\n",
      "Features: [-8898.330445141759, -9466.071018427254, -3160.0623546293, -508.91527845771435, 21390.43580348371, 3998, -1.2828983483041596]\n",
      "Scaled Features: [[-3.78906662 -2.3117115  -1.04603962 -0.62076669  0.78326799  7.85558431\n",
      "  -0.91354637]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 6.157410037144643e-14%\n",
      "Index:  13\n",
      "Features: [-138.98019888515742, -120.34599897349617, 698.4177941948278, 554.4716078695405, 19649.198916405334, 164, -1.201356423564326]\n",
      "Scaled Features: [[-0.02666101 -0.29609269 -0.28159636 -0.30433466 -0.02968286 -0.62073836\n",
      "  -0.85028174]]\n",
      "Verdict: 1\n",
      "Probability of being AI: 93.18412591027109%\n",
      "Index:  14\n",
      "Features: [-3796.5590034639604, -3811.24174768778, -967.3693536339475, -341.5988842895979, 23727.470391988718, 1373, -1.2828983483041596]\n",
      "Scaled Features: [[-1.59770163 -1.09211856 -0.61162262 -0.57097835  1.87438562  2.05215525\n",
      "  -0.91354637]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 0.00010591949260708333%\n",
      "Index:  15\n",
      "Features: [-624.8120244636393, -512.2313910577388, -251.7273780457199, -70.77222307619176, 19805.918806311845, 308, -1.2681121579151498]\n",
      "Scaled Features: [[-0.23534046 -0.38061171 -0.46983941 -0.49038846  0.04348672 -0.30237882\n",
      "  -0.90207444]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 6.634847801344766%\n",
      "Index:  16\n",
      "Features: [-2902.3782265820696, -2762.244015055666, -512.5548790854293, -85.82948532832587, 27889.335493641145, 885, -1.2828983483041596]\n",
      "Scaled Features: [[-1.21362397 -0.86587827 -0.52151463 -0.49486905  3.81748239  0.97327016\n",
      "  -0.91354637]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 0.0004393631710383121%\n",
      "Index:  17\n",
      "Features: [-1737.7218012951018, -1628.4967306536025, -413.8688311740426, -0.47769022555477636, 23980.539020567274, 1328, -1.201356423564326]\n",
      "Scaled Features: [[-0.71336884 -0.6213598  -0.50196292 -0.46947092  1.99253861  1.9526679\n",
      "  -0.85028174]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 0.13156583220584692%\n",
      "Index:  18\n",
      "Features: [-2545.2625549231734, -1893.3839515910822, -580.8154895617259, -50.82480469760855, 22312.36434699258, 1051, -1.2828983483041596]\n",
      "Scaled Features: [[-1.06023199 -0.67848877 -0.53503845 -0.48445271  1.21369914  1.34026796\n",
      "  -0.91354637]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 0.044461423903229276%\n",
      "Index:  19\n",
      "Features: [-6516.757966171053, -5339.274683818469, -1567.2413441408917, -194.48854378391815, 19065.496496673088, 2593, -1.2828983483041596]\n",
      "Scaled Features: [[-2.76610928 -1.42167372 -0.73046944 -0.52720273 -0.30220258  4.749368\n",
      "  -0.91354637]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 7.472322610940792e-08%\n",
      "Index:  20\n",
      "Features: [-4778.171536467663, -3728.4041203425527, -1688.4299196318998, -81.10664644726853, 20558.023650920208, 2108, -1.2828983483041596]\n",
      "Scaled Features: [[-2.01933387 -1.07425274 -0.75447936 -0.49346368  0.39463036  3.67711539\n",
      "  -0.91354637]]\n",
      "Verdict: 0\n",
      "Probability of being AI: 1.3485570423215443e-05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "testdata = pd.read_csv('undetectable.csv')\n",
    "\n",
    "testdata = testdata['text'].to_list()\n",
    "lower = 1\n",
    "for i in range(lower, 21):\n",
    "\n",
    "    if lower == 1:\n",
    "        # with open(f'human/human{i}.txt', 'r') as file:\n",
    "        #     text = file.read()\n",
    "        # with open(f'gpt/gpt3.5-{i}.txt', 'r') as file:\n",
    "        #     text = file.read()\n",
    "        # with open(f'humanWikipedia/article{i}.txt', 'r') as file:\n",
    "        #     text = file.read()\n",
    "        with open(f'Wikipedia/human{i}.txt', 'r') as file:\n",
    "            text = file.read()\n",
    "    \n",
    "    if (lower == 0):\n",
    "        text = testdata[i]\n",
    "        if i > 3:\n",
    "            break\n",
    "\n",
    "    features = []\n",
    "        \n",
    "    for feature in x_features:\n",
    "        if (feature == 'complexity'):\n",
    "            features.append(calculate_complexity(text))\n",
    "        if (feature == 'prevalence'):\n",
    "            features.append(get_prevalence_text(text))\n",
    "        if (feature == 'bigram_prevalence'):\n",
    "            features.append(get_text_bigram_prevalence(text))\n",
    "        if (feature == 'trigram_prevalence'):\n",
    "            features.append(get_text_trigram_prevalence(text))\n",
    "        if (feature == 'sentence_std'):\n",
    "            features.append(get_text_sentence_std(text))\n",
    "        if (feature == 'readability'):\n",
    "            features.append(textstat.flesch_reading_ease(text))\n",
    "        if (feature == 'average_prevalence'):\n",
    "            features.append(get_text_average_prevalence(text))\n",
    "        if (feature == 'median_prevalence'):\n",
    "            features.append(get_text_median_prevalence(text))\n",
    "        if (feature == 'prevalence_std'):\n",
    "            features.append(get_text_prevalence_std(text))\n",
    "        if (feature == 'variance'):\n",
    "            features.append(get_text_variance(text))\n",
    "        if (feature == 'number_percentage'):\n",
    "            features.append(get_text_number_percentage(text))\n",
    "        if (feature == 'bigram_prevalence_std'):\n",
    "            features.append(get_text_bigram_prevalence_std(text))\n",
    "        if (feature == 'bigram_prevalence_mean'):\n",
    "            features.append(get_text_bigram_prevalence_mean(text))\n",
    "        if (feature == 'bigram_prevalence_median'):\n",
    "            features.append(get_text_bigram_prevalence_median(text))\n",
    "        if (feature == 'paragraph_std'):\n",
    "            features.append(get_paragraph_std(text))\n",
    "        if (feature == 'length'):\n",
    "            features.append(get_text_length(text))\n",
    "        if (feature == 'median_complexity'):\n",
    "            features.append(get_text_median_complexity(text))\n",
    "        if (feature == 'percentage_of_words_in_prevalence_table'):\n",
    "            features.append(get_text_percentage_of_words_in_prevalence_table(text))\n",
    "        if (feature == 'average_paragraph_length'):\n",
    "            features.append(get_average_paragraph_length(text))\n",
    "        if (feature == 'fourgram_prevalence'):\n",
    "            features.append(get_text_fourgram_prevalence(text))\n",
    "        if (feature == 'percentage_capitalized'):\n",
    "            features.append(percentage_of_capitalized_words(text))\n",
    "        if (feature == 'fivegram_prevalence'):\n",
    "            features.append(get_text_fivegram_prevalence(text))\n",
    " \n",
    "#    IMPORTANT: Transform the new features using the same scaler used for the training data\n",
    "    features_scaled = scaler.transform([features])  # Note: scaler.transform expects a 2D array\n",
    "# unscaled features\n",
    "    print(\"Index: \", i)\n",
    "    print(f\"Features: {features}\")\n",
    "# Make a prediction with the scaled features\n",
    "    verdict = mlp_clf.predict(features_scaled)\n",
    "    proba = mlp_clf.predict_proba(features_scaled)\n",
    "    \n",
    "    print(f\"Scaled Features: {features_scaled}\")\n",
    "    print(f\"Verdict: {verdict[0]}\")\n",
    "    print(f\"Probability of being AI: {proba[0][1]*100}%\")\n",
    "    #print(text)\n",
    "\n",
    "# average_length = pd.read_csv('megaset4.csv')['length'].mean()\n",
    "# print(average_length)\n",
    "\n",
    "# with open(f'input.txt', 'r') as file:\n",
    "#         text = file.read()\n",
    "# features = []\n",
    "# for feature in x_features:\n",
    "#         if (feature == 'complexity'):\n",
    "#             features.append(calculate_complexity(text))\n",
    "#         if (feature == 'prevalence'):\n",
    "#             features.append(get_prevalence_text(text))\n",
    "#         if (feature == 'bigram_prevalence'):\n",
    "#             features.append(get_text_bigram_prevalence(text))\n",
    "#         if (feature == 'trigram_prevalence'):\n",
    "#             features.append(get_text_trigram_prevalence(text))\n",
    "#         if (feature == 'sentence_std'):\n",
    "#             features.append(get_text_sentence_std(text))\n",
    "#         if (feature == 'readability'):\n",
    "#             features.append(textstat.flesch_reading_ease(text))\n",
    "#         if (feature == 'average_prevalence'):\n",
    "#             features.append(get_text_average_prevalence(text))\n",
    "#         if (feature == 'median_prevalence'):\n",
    "#             features.append(get_text_median_prevalence(text))\n",
    "#         if (feature == 'prevalence_std'):\n",
    "#             features.append(get_text_prevalence_std(text))\n",
    "#         if (feature == 'variance'):\n",
    "#             features.append(get_text_variance(text))\n",
    "#         if (feature == 'number_percentage'):\n",
    "#             features.append(get_text_number_percentage(text))\n",
    "#         if (feature == 'bigram_prevalence_std'):\n",
    "#             features.append(get_text_bigram_prevalence_std(text))\n",
    "#         if (feature == 'bigram_prevalence_mean'):\n",
    "#             features.append(get_text_bigram_prevalence_mean(text))\n",
    "#         if (feature == 'bigram_prevalence_median'):\n",
    "#             features.append(get_text_bigram_prevalence_median(text))\n",
    "#         if (feature == 'paragraph_std'):\n",
    "#             features.append(get_paragraph_std(text))\n",
    "#         if (feature == 'length'):\n",
    "#             features.append(get_text_length(text))\n",
    "#         if (feature == 'median_complexity'):\n",
    "#             features.append(get_text_median_complexity(text))\n",
    "#         if (feature == 'percentage_of_words_in_prevalence_table'):\n",
    "#             features.append(get_text_percentage_of_words_in_prevalence_table(text))\n",
    "#         if (feature == 'average_paragraph_length'):\n",
    "#             features.append(get_average_paragraph_length(text))\n",
    "# features_scaled = scaler.transform([features])  # Note: scaler.transform expects a 2D array\n",
    "# verdict = mlp_clf.predict(features_scaled)\n",
    "# proba = mlp_clf.predict_proba(features_scaled)\n",
    "# print(f\"Features: {features}\")\n",
    "# print(f\"Scaled Features: {features_scaled}\")\n",
    "# print(f\"Verdict: {verdict[0]}\")\n",
    "# print(f\"Probability of being AI: {proba[0][1] * 100:.2f}%\")\n",
    "# print (text)\n",
    "# print(\"prev: \",get_text_trigram_prevalence(text))\n",
    "# prev = three_word_prevalence_dict.get(' '.join(('and', 'personal', 'growth')), 0)\n",
    "# print(prev)\n",
    "# trigram dic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and save missclasifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import shutil\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to clean directories\n",
    "def prepare_directory(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Function to save texts\n",
    "def save_texts(texts, indices, directory):\n",
    "    for i, index in enumerate(indices, start=1):\n",
    "        with open(f\"{directory}/text_{i}.txt\", 'w', encoding='utf-8') as file:\n",
    "            file.write(texts.iloc[index])\n",
    "\n",
    "# Load the training dataset\n",
    "# path_train = \"megaset4.csv\"\n",
    "# train_data = pd.read_csv(path_train)\n",
    "\n",
    "# # Load the testing dataset\n",
    "# path_test = \"final_test2.csv\"\n",
    "# test_data = pd.read_csv(path_test)\n",
    "\n",
    "# # Initialize the StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Specify the feature names\n",
    "# x_features = ['complexity', 'prevalence', 'bigram_prevalence', 'trigram_prevalence', \n",
    "#               'sentence_std', 'readability', 'average_prevalence', 'median_prevalence', \n",
    "#               'prevalence_std', 'variance', 'number_percentage', 'bigram_prevalence_std', \n",
    "#               'bigram_prevalence_mean', 'bigram_prevalence_median']\n",
    "\n",
    "# # Prepare the features and target for the training data\n",
    "# X_train = train_data[x_features]\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train = train_data['generated']\n",
    "\n",
    "# Prepare the features and target for the testing data\n",
    "X_test = test_data[x_features]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test = test_data['generated']\n",
    "\n",
    "# Initialize and train MLPClassifier\n",
    "# mlp_clf = MLPClassifier(hidden_layer_sizes=(150), activation='relu', solver='adam', max_iter=400, random_state=12)\n",
    "# mlp_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = mlp_clf.predict(X_test_scaled)\n",
    "y_pred_train = mlp_clf.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Output accuracies\n",
    "print(f\"Accuracy on the training set: {accuracy_train * 100:.2f}%\")\n",
    "print(f\"Accuracy on the test set: {accuracy_test * 100:.2f}%\")\n",
    "\n",
    "# Calculate and output rates\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = conf_matrix_test.ravel()\n",
    "false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "print(f\"False Positive Rate on test data: {false_positive_rate * 100:.2f}%\")\n",
    "print(f\"False Negative Rate on test data: {false_negative_rate * 100:.2f}%\")\n",
    "print(f\"Average error rate on test data: {(false_positive_rate*100 + false_negative_rate*100) / 2 :.2f}%\")\n",
    "print(\"Confusion Matrix for the test data:\")\n",
    "print(conf_matrix_test)\n",
    "\n",
    "# Prepare directories\n",
    "prepare_directory('false_positives')\n",
    "prepare_directory('false_negatives')\n",
    "\n",
    "# Identify false positives and negatives\n",
    "fp_indices = test_data[(y_test == 0) & (y_pred_test == 1)].index\n",
    "fn_indices = test_data[(y_test == 1) & (y_pred_test == 0)].index\n",
    "\n",
    "# Save false positives and negatives to files\n",
    "save_texts(test_data['text'], fp_indices, 'false_positives')\n",
    "save_texts(test_data['text'], fn_indices, 'false_negatives')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "  \n",
    "# Load the dataset\n",
    "path = \"final_test2.csv\"  # replace with your actual path\n",
    "dataset = pd.read_csv(path)\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "column2 = 'fivegram_prevalence'\n",
    "# Plot generated == 0 in blue\n",
    "plt.scatter(dataset[dataset['generated'] == 0][column2], \n",
    "            dataset[dataset['generated'] == 0]['prevalence'], \n",
    "            c='blue', label='Human (generated=0)', alpha=0.6)\n",
    "\n",
    "# Plot generated == 1 in red\n",
    "plt.scatter(dataset[dataset['generated'] == 1][column2], \n",
    "            dataset[dataset['generated'] == 1]['prevalence'], \n",
    "            c='red', label='AI (generated=1)', alpha=0.6)\n",
    "\n",
    "plt.title(f'{column2} vs Prevalence by Origin')\n",
    "plt.xlabel(column2)\n",
    "plt.ylabel('Prevalence')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "  \n",
    "# Load the dataset\n",
    "path = \"final_test2.csv\"  # replace with your actual path\n",
    "path = \"megaset4.csv\"  # replace with your actual path\n",
    "dataset = pd.read_csv(path)\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "column2 = 'bigram_prevalence'\n",
    "# Plot generated == 0 in blue\n",
    "plt.scatter(dataset[dataset['generated'] == 0][column2], \n",
    "            dataset[dataset['generated'] == 0]['prevalence'], \n",
    "            c='blue', label='Human (generated=0)', alpha=0.6)\n",
    "\n",
    "# Plot generated == 1 in red\n",
    "plt.scatter(dataset[dataset['generated'] == 1][column2], \n",
    "            dataset[dataset['generated'] == 1]['prevalence'], \n",
    "            c='red', label='AI (generated=1)', alpha=0.6)\n",
    "\n",
    "plt.title(f'{column2} vs Prevalence by Origin')\n",
    "plt.xlabel(column2)\n",
    "plt.ylabel('Prevalence')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Load the dataset\n",
    "path = \"final_test2.csv\"  # replace with your actual path\n",
    "dataset = pd.read_csv(path).sample(50)\n",
    "\n",
    "# Creating a 3D plot\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "column2 = 'bigram_prevalence'\n",
    "column3 = 'trigram_prevalence'\n",
    "\n",
    "# Plot generated == 0 in blue\n",
    "ax.scatter(dataset[dataset['generated'] == 0][column2], \n",
    "           dataset[dataset['generated'] == 0]['prevalence'], \n",
    "           dataset[dataset['generated'] == 0][column3], \n",
    "           c='blue', label='Human (generated=0)', alpha=0.6)\n",
    "\n",
    "# Plot generated == 1 in red\n",
    "ax.scatter(dataset[dataset['generated'] == 1][column2], \n",
    "           dataset[dataset['generated'] == 1]['prevalence'], \n",
    "           dataset[dataset['generated'] == 1][column3], \n",
    "           c='red', label='AI (generated=1)', alpha=0.6)\n",
    "\n",
    "ax.set_title(f'{column2}, {column3} vs Prevalence by Origin')\n",
    "ax.set_xlabel(column2)\n",
    "ax.set_ylabel('Prevalence')\n",
    "ax.set_zlabel(column3)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
